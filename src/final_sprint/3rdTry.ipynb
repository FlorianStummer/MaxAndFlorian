{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import data.datasets as dataSource\n",
    "import torch.utils.data as tdata\n",
    "import numpy as np\n",
    "import scipy.constants as _scipy_constants\n",
    "\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B_design', 'aper_x', 'aper_y', 'fieldTolerance', 'maxCurrentDensity', 'rho0', 'w_leg_factor', 'usedPowerInPercent']\n",
      "['fieldTolerance', 'maxCurrentDensity', 'rho0', 'usedPowerInPercent', 'w_leg_factor', 'B_design', 'aper_x', 'aper_y']\n"
     ]
    }
   ],
   "source": [
    "dataset_train, dataset_val = dataSource.Dipole_H_train, dataSource.Dipole_H_val\n",
    "#print(dataset_train.input_columns)\n",
    "batch_size = 64\n",
    "important_cols = [\"B_design\",\"aper_x\", \"aper_y\", \"fieldTolerance\", \"maxCurrentDensity\" , \"rho0\", \"w_leg_factor\", \"usedPowerInPercent\"]\n",
    "important_cols_order = sorted(important_cols,key=lambda c: dataset_train.input_columns.index(c))\n",
    "\n",
    "print(important_cols)\n",
    "print(important_cols_order)\n",
    "\n",
    "input_mask = [True if col in important_cols else False for col in dataset_train.input_columns]\n",
    "train_loader, val_loader = tdata.DataLoader(dataset_train,batch_size), tdata.DataLoader(dataset_val,batch_size)\n",
    "\n",
    "target_index_dict = {col:i for i,col in enumerate(dataset_train.target_columns)}\n",
    "target_cols = [\"B0\",\"gfr_x_1e-3\",\"gfr_y_1e-3\"]\n",
    "output_mask = [True if col in target_cols else False for col in dataset_train.target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "oid = {key : important_cols.index(key) for key in important_cols_order}\n",
    "\n",
    "def get_dipole_continuous(x: torch.Tensor):\n",
    "    # x.shape = (b,7) with batchDim b and 6 \"actual\" inputs 'important cols'\n",
    "    aper_x = x[:,oid[\"aper_x\"]]\n",
    "    aper_y = x[:,oid[\"aper_y\"]]\n",
    "    maxCurrentDensity = x[:,oid[\"maxCurrentDensity\"]]\n",
    "    fieldTolerance = x[:,oid[\"fieldTolerance\"]]\n",
    "    B_design = x[:,oid[\"B_design\"]]\n",
    "    rho0 = x[:,oid[\"rho0\"]]\n",
    "    w_leg_factor = x[:,oid[\"w_leg_factor\"]]\n",
    "    usedPowerInPercent = x[:,oid[\"usedPowerInPercent\"]]\n",
    "\n",
    "    xnorm_unoptimised = -0.36 * torch.log(fieldTolerance) - 0.90\n",
    "    xnorm_optimised = -0.14 * torch.log(fieldTolerance) - 0.25\n",
    "    gfr_x = aper_x * rho0\n",
    "    gfr_y = aper_y * rho0\n",
    "    dipole_corner_norm_0 = rho0**2+xnorm_unoptimised\n",
    "    polecorner_x = aper_x + xnorm_unoptimised * aper_y\n",
    "\n",
    "    w = 2*polecorner_x + 2 * polecorner_x * 0.05\n",
    "    w_leg = 0.5 * (w + 2 * aper_y) * B_design / 2.15 * w_leg_factor\n",
    "\n",
    "    totalCurrentDesign = B_design * aper_y / (2 * _scipy_constants.mu_0)\n",
    "    totalCurrent = usedPowerInPercent * 0.01 * totalCurrentDesign\n",
    "\n",
    "    A_min = totalCurrentDesign / 1e6 / (maxCurrentDensity * (75 * 0.01))\n",
    "    coil_width = (A_min *2) ** 0.5\n",
    "    coil_height = coil_width * 0.5\n",
    "    \n",
    "    stack = torch.cat([\n",
    "        x,\n",
    "        gfr_x.unsqueeze(1),\n",
    "        gfr_y.unsqueeze(1),\n",
    "        xnorm_unoptimised.unsqueeze(1),\n",
    "        xnorm_optimised.unsqueeze(1),\n",
    "        dipole_corner_norm_0.unsqueeze(1),\n",
    "        polecorner_x.unsqueeze(1),\n",
    "        w.unsqueeze(1),\n",
    "        w_leg.unsqueeze(1),\n",
    "        totalCurrentDesign.unsqueeze(1),\n",
    "        totalCurrent.unsqueeze(1),\n",
    "        coil_width.unsqueeze(1),\n",
    "        coil_height.unsqueeze(1),\n",
    "        A_min.unsqueeze(1),\n",
    "        ],dim=1)\n",
    "    return stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class MyRegNet(nn.Module):\n",
    "    def __init__(self,h_size=32):\n",
    "        super().__init__()\n",
    "        self.bn0 = nn.BatchNorm1d(len(important_cols)+13, dtype=torch.double)\n",
    "        self.fc1 = nn.Linear(len(important_cols)+13,h_size, dtype=torch.double)\n",
    "        self.nl1 = nn.LeakyReLU()\n",
    "        self.bn1 = nn.BatchNorm1d(h_size, dtype=torch.double)\n",
    "        self.do1 = nn.Dropout1d()\n",
    "        self.fc2 = nn.Linear(h_size,h_size, dtype=torch.double)\n",
    "        self.nl2 = nn.LeakyReLU()\n",
    "        self.bn2 = nn.BatchNorm1d(h_size, dtype=torch.double)\n",
    "        self.do2 = nn.Dropout1d()\n",
    "        self.fc3 = nn.Linear(h_size,3, dtype=torch.double)\n",
    "    def forward(self,x):\n",
    "        x = get_dipole_continuous(x)\n",
    "        x = self.bn0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.nl1(x)\n",
    "        x = self.bn1(x)\n",
    "        #x = self.do1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.nl2(x)\n",
    "        x = self.bn2(x)\n",
    "        #x = self.do2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "network = MyRegNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mask_df = dataset_train.dataframe[[\"B0\",\"gfr_x_1e-3\",\"gfr_y_1e-3\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 tensor(0.0023) tensor(0.0011)\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1110960/848859318.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mselected_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mselected_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_IterableDataset_len_called\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/florian/MaxAndFlorian/src/final_sprint/data/datasets.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1755\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3984\u001b[0m             \u001b[0mnew_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3986\u001b[0m             \u001b[0;31m# if we are a copy, mark as such\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3987\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnew_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3988\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3989\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3990\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3991\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, mgr, axes)\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_constructor_sliced_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sliced_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# caller is responsible for setting real name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "lr = 5e-5\n",
    "optim = torch.optim.Adam(network.parameters(), lr)\n",
    "loss_fun = nn.MSELoss()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    network.train()\n",
    "    loss_list = []\n",
    "    for x,y in train_loader:\n",
    "        selected_x = x[:,input_mask].double().to(device)\n",
    "        selected_y = y[:,output_mask].double().to(device)\n",
    "        pred = network(selected_x)\n",
    "\n",
    "        #loss_mask = (torch.tensor(list(loss_mask_df))* torch.tensor([10,1,1])).repeat((x.shape[0],1)).to(device)\n",
    "        loss = loss_fun(pred,selected_y)\n",
    "        loss_list.append(loss.detach().item())\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    epoch_train_loss = torch.tensor(loss_list).mean()\n",
    "\n",
    "    network.eval()\n",
    "    loss_list = []\n",
    "    for x,y in val_loader:\n",
    "        selected_x = x[:,input_mask].double().to(device)\n",
    "        selected_y = y[:,output_mask].double().to(device)\n",
    "        pred = network(selected_x)\n",
    "\n",
    "        #loss_mask = (torch.tensor(list(loss_mask_df))* torch.tensor([10,1,1])).repeat((x.shape[0],1)).to(device)\n",
    "        loss = loss_fun(pred ,selected_y )\n",
    "        loss_list.append(loss.detach().item())\n",
    "    epoch_val_loss = torch.tensor(loss_list).mean()\n",
    "    print(epoch,epoch_train_loss,epoch_val_loss,end=\"\\r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), \"network_design_params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1110960/1750107852.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  network.load_state_dict(torch.load(\"network_design_params\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "network = MyRegNet().to(device)\n",
    "network.load_state_dict(torch.load(\"network_design_params\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abs': {'B0': 0.03093236719500123, 'gfr_x': 0.014907938658596584, 'gfr_y': 0.005870515391147503}, 'rel': {'B0': 0.08968141834874543, 'gfr_x': 0.13212382808958228, 'gfr_y': 0.17390795346346155}}\n"
     ]
    }
   ],
   "source": [
    "errors = {error_type: {\"B0\":[],\"gfr_x\":[],\"gfr_y\":[]} for error_type in [\"abs\",\"rel\"]}\n",
    "\n",
    "single_sample_loader =  tdata.DataLoader(dataset_val, 1)\n",
    "\n",
    "network.eval()\n",
    "for x,y in single_sample_loader:\n",
    "    \n",
    "    selected_x = x[:,input_mask].double().to(device)\n",
    "    selected_y = y[:,output_mask].double().to(device)\n",
    "    pred = network(selected_x)\n",
    "    #print(pred,selected_y)\n",
    "    abs_errors = torch.abs(pred - selected_y)\n",
    "    errors[\"abs\"][\"B0\"].append(abs_errors[:,0].detach().item())\n",
    "    errors[\"abs\"][\"gfr_x\"].append(abs_errors[:,1].detach().item())\n",
    "    errors[\"abs\"][\"gfr_y\"].append(abs_errors[:,2].detach().item())\n",
    "\n",
    "    rel_errors = torch.abs(1 - (pred/selected_y))\n",
    "    errors[\"rel\"][\"B0\"].append(rel_errors[:,0].detach().item())\n",
    "    errors[\"rel\"][\"gfr_x\"].append(rel_errors[:,1].detach().item())\n",
    "    errors[\"rel\"][\"gfr_y\"].append(rel_errors[:,2].detach().item())\n",
    "mean_errors = {error_type: {quantity: sum(v)/len(v) for quantity, v in dictt.items()} for error_type, dictt in errors.items() }\n",
    "print(mean_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = []\n",
    "b = []\n",
    "\n",
    "def onehot(name, neg):\n",
    "    out = [0] * len(important_cols_order)\n",
    "    out[important_cols_order.index(name)] = -1 if neg else 1\n",
    "    return out\n",
    "\n",
    "for name in important_cols_order:\n",
    "    # constraints for minima: x > a --> -x < -a\n",
    "    A.append(onehot(name,True))\n",
    "    b.append(-dataset_train.input_mins[name])\n",
    "    \n",
    "    # constraints for maxima: x < a\n",
    "    if name == \"usedPowerInPercent\":\n",
    "        A.append(onehot(name,False))\n",
    "        b.append(100)\n",
    "    else:\n",
    "        A.append(onehot(name,False))\n",
    "        b.append(dataset_train.input_maxs[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_rel = []\n",
    "b_rel = []\n",
    "\n",
    "#['fieldTolerance', 'maxCurrentDensity', 'rho0', 'usedPowerInPercent', 'w_leg_factor', 'B_design', 'aper_x', 'aper_y']\n",
    "\n",
    "# aper_x > aper_y --> aper_y - aper_x < 0\n",
    "A_rel.append([0, 0, 0, 0, 0, 0, -1, 1])\n",
    "b_rel.append(0)\n",
    "\n",
    "# aper_x < 5 * aper_y --> aper_x - 5 * aper_y < 0\n",
    "A_rel.append([0, 0, 0, 0, 0, 0, 1, -3])\n",
    "b_rel.append(0)\n",
    "\n",
    "\n",
    "\n",
    "A = A + A_rel\n",
    "b = b + b_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fieldTolerance maxCurrentDensity 1.0000100000000001e-05 0.0199998 --> [-1, 1.0000100000000001e-05, 0, 0, 0, 0, 0, 0] < 0 and [1, -0.0199998, 0, 0, 0, 0, 0, 0] < 0\n",
      "fieldTolerance rho0 0.00010000100000000001 0.0199998 --> [-1, 0, 0.00010000100000000001, 0, 0, 0, 0, 0] < 0 and [1, 0, -0.0199998, 0, 0, 0, 0, 0] < 0\n",
      "fieldTolerance usedPowerInPercent 8.000080000000001e-07 0.0009372486996250448 --> [-1, 0, 0, 8.000080000000001e-07, 0, 0, 0, 0] < 0 and [1, 0, 0, -0.0009372486996250448, 0, 0, 0, 0] < 0\n",
      "fieldTolerance w_leg_factor 4.12525439843647e-05 0.012253019520256961 --> [-1, 0, 0, 0, 4.12525439843647e-05, 0, 0, 0] < 0 and [1, 0, 0, 0, -0.012253019520256961, 0, 0, 0] < 0\n",
      "fieldTolerance B_design 5.0000500000000003e-05 0.13557761627338663 --> [-1, 0, 0, 0, 0, 5.0000500000000003e-05, 0, 0] < 0 and [1, 0, 0, 0, 0, -0.13557761627338663, 0, 0] < 0\n",
      "fieldTolerance aper_x 0.00033333666666666674 0.33333000000000007 --> [-1, 0, 0, 0, 0, 0, 0.00033333666666666674, 0] < 0 and [1, 0, 0, 0, 0, 0, -0.33333000000000007, 0] < 0\n",
      "fieldTolerance aper_y 0.00045370780514371946 0.33333000000000007 --> [-1, 0, 0, 0, 0, 0, 0, 0.00045370780514371946] < 0 and [1, 0, 0, 0, 0, 0, 0, -0.33333000000000007] < 0\n",
      "maxCurrentDensity rho0 0.500005 19.9998 --> [0, -1, 0.500005, 0, 0, 0, 0, 0] < 0 and [0, 1, -19.9998, 0, 0, 0, 0, 0] < 0\n",
      "maxCurrentDensity usedPowerInPercent 0.004000040000000001 0.975581637535457 --> [0, -1, 0, 0.004000040000000001, 0, 0, 0, 0] < 0 and [0, 1, 0, -0.975581637535457, 0, 0, 0, 0] < 0\n",
      "maxCurrentDensity w_leg_factor 0.2107460550503864 12.427571558875425 --> [0, -1, 0, 0, 0.2107460550503864, 0, 0, 0] < 0 and [0, 1, 0, 0, -12.427571558875425, 0, 0, 0] < 0\n",
      "maxCurrentDensity B_design 0.2500025 214.13971628552005 --> [0, -1, 0, 0, 0, 0.2500025, 0, 0] < 0 and [0, 1, 0, 0, 0, -214.13971628552005, 0, 0] < 0\n",
      "maxCurrentDensity aper_x 1.6666833333333335 333.33000000000004 --> [0, -1, 0, 0, 0, 0, 1.6666833333333335, 0] < 0 and [0, 1, 0, 0, 0, 0, -333.33000000000004, 0] < 0\n",
      "maxCurrentDensity aper_y 1.6666833333333335 333.33000000000004 --> [0, -1, 0, 0, 0, 0, 0, 1.6666833333333335] < 0 and [0, 1, 0, 0, 0, 0, 0, -333.33000000000004] < 0\n",
      "rho0 usedPowerInPercent 0.004000040000000001 0.09835029804976969 --> [0, 0, -1, 0.004000040000000001, 0, 0, 0, 0] < 0 and [0, 0, 1, -0.09835029804976969, 0, 0, 0, 0] < 0\n",
      "rho0 w_leg_factor 0.2016574818836653 1.237974897106323 --> [0, 0, -1, 0, 0.2016574818836653, 0, 0, 0] < 0 and [0, 0, 1, 0, -1.237974897106323, 0, 0, 0] < 0\n",
      "rho0 B_design 0.2500025 19.9998 --> [0, 0, -1, 0, 0, 0.2500025, 0, 0] < 0 and [0, 0, 1, 0, 0, -19.9998, 0, 0] < 0\n",
      "rho0 aper_x 1.6666833333333335 33.333000000000006 --> [0, 0, -1, 0, 0, 0, 1.6666833333333335, 0] < 0 and [0, 0, 1, 0, 0, 0, -33.333000000000006, 0] < 0\n",
      "rho0 aper_y 1.6666833333333335 33.333000000000006 --> [0, 0, -1, 0, 0, 0, 0, 1.6666833333333335] < 0 and [0, 0, 1, 0, 0, 0, 0, -33.333000000000006] < 0\n",
      "usedPowerInPercent w_leg_factor 4.081154586731156 154.3367578595707 --> [0, 0, 0, -1, 4.081154586731156, 0, 0, 0] < 0 and [0, 0, 0, 1, -154.3367578595707, 0, 0, 0] < 0\n",
      "usedPowerInPercent B_design 5.2723678893262855 2499.975 --> [0, 0, 0, -1, 0, 5.2723678893262855, 0, 0] < 0 and [0, 0, 0, 1, 0, -2499.975, 0, 0] < 0\n",
      "usedPowerInPercent aper_x 33.67481888311244 4166.625000000001 --> [0, 0, 0, -1, 0, 0, 33.67481888311244, 0] < 0 and [0, 0, 0, 1, 0, 0, -4166.625000000001, 0] < 0\n",
      "usedPowerInPercent aper_y 36.10187850010858 4166.625000000001 --> [0, 0, 0, -1, 0, 0, 0, 36.10187850010858] < 0 and [0, 0, 0, 1, 0, 0, 0, -4166.625000000001] < 0\n",
      "w_leg_factor B_design 0.40191848519640155 50.958515579199585 --> [0, 0, 0, 0, -1, 0.40191848519640155, 0, 0] < 0 and [0, 0, 0, 0, 1, -50.958515579199585, 0, 0] < 0\n",
      "w_leg_factor aper_x 2.681217140020232 77.65818803927945 --> [0, 0, 0, 0, -1, 0, 2.681217140020232, 0] < 0 and [0, 0, 0, 0, 1, 0, -77.65818803927945, 0] < 0\n",
      "w_leg_factor aper_y 2.8199520238038702 82.62014534916742 --> [0, 0, 0, 0, -1, 0, 0, 2.8199520238038702] < 0 and [0, 0, 0, 0, 1, 0, 0, -82.62014534916742] < 0\n",
      "B_design aper_x 0.15765284955543815 66.66600000000001 --> [0, 0, 0, 0, 0, -1, 0.15765284955543815, 0] < 0 and [0, 0, 0, 0, 0, 1, -66.66600000000001, 0] < 0\n",
      "B_design aper_y 0.16666833333333336 66.66600000000001 --> [0, 0, 0, 0, 0, -1, 0, 0.16666833333333336] < 0 and [0, 0, 0, 0, 0, 1, 0, -66.66600000000001] < 0\n",
      "aper_x aper_y 1.00001 2.99997 --> [0, 0, 0, 0, 0, 0, -1, 1.00001] < 0 and [0, 0, 0, 0, 0, 0, 1, -2.99997] < 0\n"
     ]
    }
   ],
   "source": [
    "# ratio constraints \n",
    "# compute min and max ratio for every pair of inputs and ensure the ratio is in that range with two linear constraints\n",
    "# e.g. min < a/b < max -->  min * b - a < 0 and a - max * b < 0\n",
    "# with slack. min * (1+e) < a/b < max * (1-e) -->  (min (1+ e)) * b - a < 0 and a - (max*(1-e)) * b < 0\n",
    "\n",
    "A_rat = []\n",
    "b_rat = []\n",
    "epsilon = 1e-5\n",
    "\n",
    "for i in range(len(important_cols_order)-1):\n",
    "    for j in range(i+1,len(important_cols_order)):\n",
    "        quantity_1 = important_cols_order[i]\n",
    "        quantity_2 = important_cols_order[j]\n",
    "\n",
    "        # ratio = column i/ colimn j\n",
    "        ratio_df = dataset_train.dataframe.assign(ratio=dataset_train.dataframe.apply(lambda r: r[quantity_1] / r[quantity_2], axis=1))\n",
    "\n",
    "        minimum = ratio_df[\"ratio\"].min() \n",
    "        maximum = ratio_df[\"ratio\"].max()\n",
    "\n",
    "        minimum *= 1+epsilon\n",
    "        maximum *= 1-epsilon\n",
    "\n",
    "        # min * j - i < 0\n",
    "        min_row = [0]*len(important_cols)\n",
    "        min_row[i] = -1\n",
    "        min_row[j] = minimum\n",
    "        A_rat.append(min_row)\n",
    "        b_rat.append(0)\n",
    "\n",
    "        #i - max * k < 0\n",
    "        max_row = [0]*len(important_cols)\n",
    "        max_row[i] = 1\n",
    "        max_row[j] = -maximum\n",
    "        A_rat.append(max_row)\n",
    "        b_rat.append(0)\n",
    "\n",
    "        print(quantity_1,quantity_2,minimum,maximum, \"-->\", min_row,\"< 0 and\", max_row,\"< 0\")\n",
    "\n",
    "\n",
    "A = A + A_rat\n",
    "b = b + b_rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_to_polytope(x, A_mat=A, b_vec = b):\n",
    "    # Define decision variable\n",
    "    p = cp.Variable(len(x))\n",
    "    # Define objective function\n",
    "    objective = cp.Minimize(cp.sum_squares(p - x))\n",
    "\n",
    "    A_mat_dynamic = A_mat[:]\n",
    "    b_vec_dynamic = b_vec[:]\n",
    "\n",
    "\n",
    "    # Define constraints\n",
    "    constraints = [np.array(A_mat) @ p <= np.array(b_vec)]\n",
    "\n",
    "    # Solve the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "\n",
    "\n",
    "    # Optimal solution\n",
    "    closest_point = p.value\n",
    "    return closest_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([1.8,0.09,0.05], device=device,dtype=torch.double)\n",
    "loss_fun = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.4896e-04, 5.1580e-01, 7.4863e-02, 7.1511e+00, 1.5748e-01, 9.5007e-02,\n",
      "        1.3921e-02, 8.8204e-03], device='cuda:0', dtype=torch.float64)\n",
      "24, 0.092023841949\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999, 0.001752467681\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.8067e-03, 5.7211e+00, 9.9266e-01, 9.3665e+01, 1.8459e+00, 2.0000e+00,\n",
       "         1.5989e-01, 1.5989e-01]], device='cuda:0', dtype=torch.float64,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init guess\n",
    "guess = torch.randn((8),dtype=torch.double)\n",
    "guess = network.bn0.running_mean[:8].clone().detach()\n",
    "\n",
    "# initially project to ensure all values make sense and the continuous transformations make sense  as well\n",
    "magnet_params = torch.tensor(project_to_polytope(guess.detach().cpu().numpy())).unsqueeze(0).to(device).requires_grad_(True)\n",
    "\n",
    "lr = 1e-1\n",
    "lr_tensor = network.bn0.running_mean[:8].clone().detach() * lr\n",
    "print(lr_tensor.clone().detach())\n",
    "network.eval()\n",
    "\n",
    "n_steps = 2000\n",
    "\n",
    "for step in range(n_steps):\n",
    "    if magnet_params.grad is not None:\n",
    "        magnet_params.grad.zero_()\n",
    "    for layer in network.parameters():\n",
    "        if layer.grad is not None:\n",
    "            layer.grad.zero_()\n",
    "\n",
    "    pred = network(magnet_params)\n",
    "    #print(pred)\n",
    "    loss = loss_fun(pred,target)\n",
    "    #print(loss)\n",
    "\n",
    "    print(f\"{step}, {loss.detach().cpu().numpy():.12f}\",end=\"\\r\")\n",
    "    loss.backward()\n",
    "    with torch.no_grad():        \n",
    "        magnet_params = magnet_params - lr_tensor * magnet_params.grad\n",
    "        proj_result = project_to_polytope(magnet_params.squeeze().detach().cpu().numpy())\n",
    "        if (proj_result is None):\n",
    "            magnet_params = torch.tensor(magnet_params).requires_grad_(True)\n",
    "        else:        \n",
    "            magnet_params = torch.tensor(proj_result).unsqueeze(0).to(device).requires_grad_(True)\n",
    "\n",
    "\n",
    "magnet_params = torch.tensor(project_to_polytope(magnet_params.squeeze().detach().cpu().numpy())).unsqueeze(0).to(device).requires_grad_(True)\n",
    "magnet_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import femmcreator\n",
    "import magnetdesigner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009795387215923832 5.964267567238819 0.9929449227917425 99.73837421491311 1.8656625112835408 1.9999921337070532 0.13590314737957584 0.10416306217856935\n"
     ]
    }
   ],
   "source": [
    "magnet_params_np = magnet_params.squeeze().detach().cpu().numpy()\n",
    "\n",
    "print(*list(*(magnet_params.detach().cpu().numpy())))\n",
    "#['fieldTolerance', 'maxCurrentDensity', 'rho0', 'usedPowerInPercent', 'w_leg_factor', 'B_design', 'aper_x', 'aper_y']\n",
    "\n",
    "magnet = magnetdesigner.designer.get_Dipole(\n",
    "    name=name, \n",
    "    B_design=magnet_params_np[5], \n",
    "    aper_x=magnet_params_np[6], \n",
    "    aper_y=magnet_params_np[7], \n",
    "    fieldTolerance=magnet_params_np[0], \n",
    "    rho0=magnet_params_np[2], \n",
    "    w_leg_factor=magnet_params_np[4],\n",
    "    maxCurrentDensity=magnet_params_np[1], \n",
    "    usedPowerInPercent=magnet_params_np[3], \n",
    "    shape=\"H\")\n",
    "\n",
    "femm = femmcreator.FEMM()\n",
    "femm.Build(magnet.get_femminput)\n",
    "femm.CreateFEMM('dipole_1.8_0.09_0.05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
