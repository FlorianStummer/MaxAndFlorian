{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import data.datasets as dataSource\n",
    "import torch.utils.data as tdata\n",
    "import numpy as np\n",
    "import scipy.constants as _scipy_constants\n",
    "\n",
    "import cvxpy as cp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B_design', 'fieldTolerance', 'maxCurrentDensity', 'aper_x', 'aper_y', 'B_real']\n",
      "['maxCurrentDensity', 'fieldTolerance', 'aper_x', 'aper_y', 'B_design', 'B_real']\n"
     ]
    }
   ],
   "source": [
    "dataset_train, dataset_val = dataSource.Dipole_H_train, dataSource.Dipole_H_val\n",
    "batch_size = 64\n",
    "important_cols = [\"B_design\", \"fieldTolerance\", \"maxCurrentDensity\", \"aper_x\", \"aper_y\", \"B_real\"]\n",
    "important_cols_order = sorted(important_cols,key=lambda c: dataset_train.input_columns.index(c))\n",
    "\n",
    "print(important_cols)\n",
    "print(important_cols_order)\n",
    "\n",
    "input_mask = [True if col in important_cols else False for col in dataset_train.input_columns]\n",
    "train_loader, val_loader = tdata.DataLoader(dataset_train,batch_size), tdata.DataLoader(dataset_val,batch_size)\n",
    "\n",
    "target_index_dict = {col:i for i,col in enumerate(dataset_train.target_columns)}\n",
    "target_cols = [\"B0\",\"gfr_x_1e-4\",\"gfr_y_1e-4\"]\n",
    "output_mask = [True if col in target_cols else False for col in dataset_train.target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2925552815282366"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.dataframe[\"B_design\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "oid = {key : important_cols.index(key) for key in important_cols_order}\n",
    "\n",
    "def get_dipole_continuous(x: torch.Tensor):\n",
    "    # x.shape = (b,6) with batchDim b and 6 \"actual\" inputs 'important cols'\n",
    "    aper_x = x[:,oid[\"aper_x\"]]\n",
    "    aper_y = x[:,oid[\"aper_y\"]]\n",
    "    maxCurrentDensity = x[:,oid[\"maxCurrentDensity\"]]\n",
    "    fieldTolerance = x[:,oid[\"fieldTolerance\"]]\n",
    "    B_design = x[:,oid[\"B_design\"]]\n",
    "    B_real = x[:,oid[\"B_real\"]]\n",
    "\n",
    "    gfr_x = aper_x - 0.015\n",
    "    gfr_y = aper_y - 0.015\n",
    "    aper_x_poleoverhang = aper_x * 0.5 * (-0.36 * torch.log(fieldTolerance) - 0.90)\n",
    "    aper_x_tapering = aper_x_poleoverhang * 0.1\n",
    "    aper_y_distFromCoil = aper_y * 0.1\n",
    "    B_max = B_design * (1 + 20 * 0.01)\n",
    "    totalCurrent = B_real * aper_y / (2 * _scipy_constants.mu_0)\n",
    "    totalCurrentMax = B_max * aper_y / (2 * _scipy_constants.mu_0)\n",
    "\n",
    "    # windings and related properties dont work exactly, as the ceil function is not continuous\n",
    "    # nevertheless, the continuous approximations could still be useful for the network\n",
    "    #windings_cont = totalCurrentMax / maxCurrent\n",
    "    \n",
    "    w = aper_x + 2 * aper_x_poleoverhang\n",
    "    w_leg = 0*5 * (w + 2 * aper_y) * B_max / 2.15\n",
    "\n",
    "    minCoilArea = totalCurrentMax / (maxCurrentDensity * (75 * 0.01)) / 1e6\n",
    "\n",
    "    coil_width = torch.sqrt(minCoilArea * 2)\n",
    "    coil_height = minCoilArea / coil_width\n",
    "\n",
    "    yoke_x = w + 2 * (aper_x_tapering + w_leg + coil_width)\n",
    "    yoke_y = aper_y + 2 * (aper_y_distFromCoil + w_leg + coil_height)\n",
    "\n",
    "    stack = torch.cat([\n",
    "        x,\n",
    "        gfr_x.unsqueeze(1),\n",
    "        gfr_y.unsqueeze(1),\n",
    "        aper_x_poleoverhang.unsqueeze(1),\n",
    "        aper_x_tapering.unsqueeze(1),\n",
    "        aper_y_distFromCoil.unsqueeze(1),\n",
    "        B_max.unsqueeze(1),\n",
    "        totalCurrent.unsqueeze(1),\n",
    "        totalCurrentMax.unsqueeze(1),\n",
    "        w.unsqueeze(1),\n",
    "        w_leg.unsqueeze(1),\n",
    "        minCoilArea.unsqueeze(1),\n",
    "        coil_width.unsqueeze(1),\n",
    "        coil_height.unsqueeze(1),\n",
    "        yoke_x.unsqueeze(1),\n",
    "        yoke_y.unsqueeze(1),\n",
    "        ],dim=1)\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRegNet(nn.Module):\n",
    "    def __init__(self,h_size=8):\n",
    "        super().__init__()\n",
    "        self.bn0 = nn.BatchNorm1d(len(important_cols)+15, dtype=torch.double)\n",
    "        self.fc1 = nn.Linear(len(important_cols)+15,h_size, dtype=torch.double)\n",
    "        self.nl1 = nn.LeakyReLU()\n",
    "        self.bn1 = nn.BatchNorm1d(h_size, dtype=torch.double)\n",
    "        #self.do1 = nn.Dropout1d(0.5)\n",
    "        #self.fc2 = nn.Linear(h_size,h_size, dtype=torch.double)\n",
    "        #self.nl2 = nn.LeakyReLU()\n",
    "        #self.bn2 = nn.BatchNorm1d(h_size, dtype=torch.double)\n",
    "        #self.do2 = nn.Dropout1d()\n",
    "        self.fc3 = nn.Linear(h_size,3, dtype=torch.double)\n",
    "    def forward(self,x):\n",
    "        x = get_dipole_continuous(x)\n",
    "        x = self.bn0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.nl1(x)\n",
    "        x = self.bn1(x)\n",
    "        #x = self.do1(x)\n",
    "        #x = self.fc2(x)\n",
    "        #x = self.nl2(x)\n",
    "        #x = self.bn2(x)\n",
    "        #x = self.do2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "network = MyRegNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mask_df = dataset_train.dataframe[[\"B0\",\"gfr_x_1e-4\",\"gfr_y_1e-4\"]].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 tensor(0.0030) tensor(0.0005)\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m network\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      8\u001b[0m loss_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     10\u001b[0m     selected_x \u001b[38;5;241m=\u001b[39m x[:,input_mask]\u001b[38;5;241m.\u001b[39mdouble()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m     selected_y \u001b[38;5;241m=\u001b[39m y[:,output_mask]\u001b[38;5;241m.\u001b[39mdouble()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/florian/MaxAndFlorian/src/final_sprint/data/datasets.py:35\u001b[0m, in \u001b[0;36m_MyDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     34\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39miloc[idx]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs, target\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1192\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1191\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1755\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m-> 1755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3984\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3982\u001b[0m \u001b[38;5;66;03m# irow\u001b[39;00m\n\u001b[1;32m   3983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3984\u001b[0m     new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_xs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3986\u001b[0m     \u001b[38;5;66;03m# if we are a copy, mark as such\u001b[39;00m\n\u001b[1;32m   3987\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(new_mgr\u001b[38;5;241m.\u001b[39marray, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m new_mgr\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:974\u001b[0m, in \u001b[0;36mBlockManager.fast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;124;03mReturn the array corresponding to `frame.iloc[loc]`.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;124;03mnp.ndarray or ExtensionArray\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;66;03m# TODO: this could be wrong if blk.mgr_locs is not slice(None)-like;\u001b[39;00m\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m#  is this ruled out in the general case?\u001b[39;00m\n\u001b[0;32m--> 974\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;66;03m# in the case of a single block, the new block is a view\u001b[39;00m\n\u001b[1;32m    976\u001b[0m     bp \u001b[38;5;241m=\u001b[39m BlockPlacement(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(result)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "lr = 1e-4\n",
    "optim = torch.optim.Adam(network.parameters(), lr)\n",
    "loss_fun = nn.MSELoss()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    network.train()\n",
    "    loss_list = []\n",
    "    for x,y in train_loader:\n",
    "        selected_x = x[:,input_mask].double().to(device)\n",
    "        selected_y = y[:,output_mask].double().to(device)\n",
    "        pred = network(selected_x)\n",
    "\n",
    "        loss_mask = (torch.tensor(list(loss_mask_df))* torch.tensor([1.5,1,1])).repeat((x.shape[0],1)).to(device)\n",
    "        loss = loss_fun(pred * loss_mask,selected_y * loss_mask)\n",
    "        loss_list.append(loss.detach().item())\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    epoch_train_loss = torch.tensor(loss_list).mean()\n",
    "\n",
    "    network.eval()\n",
    "    loss_list = []\n",
    "    for x,y in val_loader:\n",
    "        selected_x = x[:,input_mask].double().to(device)\n",
    "        selected_y = y[:,output_mask].double().to(device)\n",
    "        pred = network(selected_x)\n",
    "\n",
    "        loss_mask = (torch.tensor(list(loss_mask_df))* torch.tensor([1.5,1,1])).repeat((x.shape[0],1)).to(device)\n",
    "        loss = loss_fun(pred * loss_mask,selected_y * loss_mask)\n",
    "        loss_list.append(loss.detach().item())\n",
    "    epoch_val_loss = torch.tensor(loss_list).mean()\n",
    "    print(epoch,epoch_train_loss,epoch_val_loss,end=\"\\r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), \"network_design_params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "network = MyRegNet().to(device)\n",
    "network.load_state_dict(torch.load(\"network_design_params\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = []\n",
    "b = []\n",
    "\n",
    "def onehot(name, neg):\n",
    "    out = [0] * len(important_cols_order)\n",
    "    out[important_cols_order.index(name)] = -1 if neg else 1\n",
    "    return out\n",
    "\n",
    "for name in important_cols_order:\n",
    "    # constraints for minima: x > a --> -x < -a\n",
    "    A.append(onehot(name,True))\n",
    "    b.append(-dataset_train.input_mins[name])\n",
    "    \n",
    "    # constraints for maxima: x < a\n",
    "    A.append(onehot(name,False))\n",
    "    b.append(dataset_train.input_maxs[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_rel = []\n",
    "b_rel = []\n",
    "\n",
    "# ['maxCurrentDensity', 'fieldTolerance', 'aper_x', 'aper_y', 'B_design', 'B_real']\n",
    "\n",
    "# aper_x > aper_y --> aper_y - aper_x < 0\n",
    "A_rel.append([0, 0, -1, 1, 0, 0])\n",
    "b_rel.append(0)\n",
    "\n",
    "# aper_x < 5 * aper_y --> aper_x - 5 * aper_y < 0\n",
    "A_rel.append([0, 0, 1, -5, 0, 0])\n",
    "b_rel.append(0)\n",
    "\n",
    "# 1.2 * B_design > B_real --> B_real - 1.2 * B_design < 0\n",
    "A_rel.append([0, 0, 0, 0, -1.2, 1])\n",
    "b_rel.append(0)\n",
    "\n",
    "\n",
    "A = A + A_rel\n",
    "b = b + b_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxCurrentDensity fieldTolerance 200.00001 99999.99999 --> [-1, 200.00001, 0, 0, 0, 0] < 0 and [1, -99999.99999, 0, 0, 0, 0] < 0\n",
      "maxCurrentDensity aper_x 6.666676666666667 399.99999 --> [-1, 0, 6.666676666666667, 0, 0, 0] < 0 and [1, 0, -399.99999, 0, 0, 0] < 0\n",
      "maxCurrentDensity aper_y 6.666676666666667 399.99999 --> [-1, 0, 0, 6.666676666666667, 0, 0] < 0 and [1, 0, 0, -399.99999, 0, 0] < 0\n",
      "maxCurrentDensity B_design 1.00001 24.99999 --> [-1, 0, 0, 0, 1.00001, 0] < 0 and [1, 0, 0, 0, -24.99999, 0] < 0\n",
      "maxCurrentDensity B_real 0.8333433333333333 249.99999 --> [-1, 0, 0, 0, 0, 0.8333433333333333] < 0 and [1, 0, 0, 0, 0, -249.99999] < 0\n",
      "fieldTolerance aper_x 0.0003433333333333334 0.39998999999999996 --> [0, -1, 0.0003433333333333334, 0, 0, 0] < 0 and [0, 1, -0.39998999999999996, 0, 0, 0] < 0\n",
      "fieldTolerance aper_y 0.0003433333333333334 0.39998999999999996 --> [0, -1, 0, 0.0003433333333333334, 0, 0] < 0 and [0, 1, 0, -0.39998999999999996, 0, 0] < 0\n",
      "fieldTolerance B_design 6e-05 0.016656666666666667 --> [0, -1, 0, 0, 6e-05, 0] < 0 and [0, 1, 0, 0, -0.016656666666666667, 0] < 0\n",
      "fieldTolerance B_real 5.166666666666667e-05 0.16665666666666668 --> [0, -1, 0, 0, 0, 5.166666666666667e-05] < 0 and [0, 1, 0, 0, 0, -0.16665666666666668] < 0\n",
      "aper_x aper_y 1.00001 4.99999 --> [0, 0, -1, 1.00001, 0, 0] < 0 and [0, 0, 1, -4.99999, 0, 0] < 0\n",
      "aper_x B_design 0.01251 0.7499899999999999 --> [0, 0, -1, 0, 0.01251, 0] < 0 and [0, 0, 1, 0, -0.7499899999999999, 0] < 0\n",
      "aper_x B_real 0.010426666666666667 7.49999 --> [0, 0, -1, 0, 0, 0.010426666666666667] < 0 and [0, 0, 1, 0, 0, -7.49999] < 0\n",
      "aper_y B_design 0.01251 0.7499899999999999 --> [0, 0, 0, -1, 0.01251, 0] < 0 and [0, 0, 0, 1, -0.7499899999999999, 0] < 0\n",
      "aper_y B_real 0.010426666666666667 7.49999 --> [0, 0, 0, -1, 0, 0.010426666666666667] < 0 and [0, 0, 0, 1, 0, -7.49999] < 0\n",
      "B_design B_real 0.8333433333333332 9.99999 --> [0, 0, 0, 0, -1, 0.8333433333333332] < 0 and [0, 0, 0, 0, 1, -9.99999] < 0\n"
     ]
    }
   ],
   "source": [
    "# ratio constraints \n",
    "# compute min and max ratio for every pair of inputs and ensure the ratio is in that range with two linear constraints\n",
    "# e.g. min < a/b < max -->  min * b - a < 0 and a - max * b < 0\n",
    "# with slack. min * (1+e) < a/b < max * (1-e) -->  (min (1+ e)) * b - a < 0 and a - (max*(1-e)) * b < 0\n",
    "\n",
    "A_rat = []\n",
    "b_rat = []\n",
    "epsilon = 1e-5\n",
    "\n",
    "for i in range(len(important_cols_order)-1):\n",
    "    for j in range(i+1,len(important_cols_order)):\n",
    "        quantity_1 = important_cols_order[i]\n",
    "        quantity_2 = important_cols_order[j]\n",
    "\n",
    "        # ratio = column i/ colimn j\n",
    "        ratio_df = dataset_train.dataframe.assign(ratio=dataset_train.dataframe.apply(lambda r: r[quantity_1] / r[quantity_2], axis=1))\n",
    "\n",
    "        minimum = ratio_df[\"ratio\"].min() \n",
    "        maximum = ratio_df[\"ratio\"].max()\n",
    "\n",
    "        minimum *= 1+epsilon\n",
    "        maximum *= 1-epsilon\n",
    "\n",
    "        # min * j - i < 0\n",
    "        min_row = [0]*6\n",
    "        min_row[i] = -1\n",
    "        min_row[j] = minimum\n",
    "        A_rat.append(min_row)\n",
    "        b_rat.append(0)\n",
    "\n",
    "        #i - max * k < 0\n",
    "        max_row = [0]*6\n",
    "        max_row[i] = 1\n",
    "        max_row[j] = -maximum\n",
    "        A_rat.append(max_row)\n",
    "        b_rat.append(0)\n",
    "\n",
    "        print(quantity_1,quantity_2,minimum,maximum, \"-->\", min_row,\"< 0 and\", max_row,\"< 0\")\n",
    "\n",
    "\n",
    "A = A + A_rat\n",
    "b = b + b_rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 1. ])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def project_to_poly2(x, A_mat=A, b_vec = b):\n",
    "    # Define decision variable\n",
    "    p = cp.Variable(len(x))\n",
    "    # Define objective function\n",
    "    objective = cp.Minimize(cp.sum_squares(p - x))\n",
    "\n",
    "    A_mat_dynamic = A_mat[:]\n",
    "    b_vec_dynamic = b_vec[:]\n",
    "\n",
    "\n",
    "    # Define constraints\n",
    "    constraints = [np.array(A_mat) @ p <= np.array(b_vec)]\n",
    "\n",
    "    # Solve the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "\n",
    "\n",
    "    # Optimal solution\n",
    "    closest_point = p.value\n",
    "    return closest_point\n",
    "\n",
    "A_test = [[0,1],[1,0]]\n",
    "b_test = [1,1]\n",
    "project_to_poly2([0.5,1.2],A_test,b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([-1, 0, 0, 0, 0, 0], -2.0),\n",
       " ([1, 0, 0, 0, 0, 0], 10.0),\n",
       " ([0, -1, 0, 0, 0, 0], -0.0001),\n",
       " ([0, 1, 0, 0, 0, 0], 0.01),\n",
       " ([0, 0, -1, 0, 0, 0], -0.025),\n",
       " ([0, 0, 1, 0, 0, 0], 0.3),\n",
       " ([0, 0, 0, -1, 0, 0], -0.025),\n",
       " ([0, 0, 0, 1, 0, 0], 0.3),\n",
       " ([0, 0, 0, 0, -1, 0], -0.4),\n",
       " ([0, 0, 0, 0, 1, 0], 2.0),\n",
       " ([0, 0, 0, 0, 0, -1], -0.04),\n",
       " ([0, 0, 0, 0, 0, 1], 2.4),\n",
       " ([0, 0, -1, 1, 0, 0], 0),\n",
       " ([0, 0, 1, -5, 0, 0], 0),\n",
       " ([0, 0, 0, 0, -1.2, 1], 0),\n",
       " ([-1, 200.0, 0, 0, 0, 0], 0),\n",
       " ([1, -100000.0, 0, 0, 0, 0], 0),\n",
       " ([-1, 0, 6.666666666666667, 0, 0, 0], 0),\n",
       " ([1, 0, -400.0, 0, 0, 0], 0),\n",
       " ([-1, 0, 0, 6.666666666666667, 0, 0], 0),\n",
       " ([1, 0, 0, -400.0, 0, 0], 0),\n",
       " ([-1, 0, 0, 0, 1.0, 0], 0),\n",
       " ([1, 0, 0, 0, -25.0, 0], 0),\n",
       " ([-1, 0, 0, 0, 0, 0.8333333333333334], 0),\n",
       " ([1, 0, 0, 0, 0, -250.0], 0),\n",
       " ([0, -1, 0.0003333333333333334, 0, 0, 0], 0),\n",
       " ([0, 1, -0.39999999999999997, 0, 0, 0], 0),\n",
       " ([0, -1, 0, 0.0003333333333333334, 0, 0], 0),\n",
       " ([0, 1, 0, -0.39999999999999997, 0, 0], 0),\n",
       " ([0, -1, 0, 0, 5e-05, 0], 0),\n",
       " ([0, 1, 0, 0, -0.016666666666666666, 0], 0),\n",
       " ([0, -1, 0, 0, 0, 4.166666666666667e-05], 0),\n",
       " ([0, 1, 0, 0, 0, -0.16666666666666669], 0),\n",
       " ([0, 0, -1, 1.0, 0, 0], 0),\n",
       " ([0, 0, 1, -5.0, 0, 0], 0),\n",
       " ([0, 0, -1, 0, 0.0125, 0], 0),\n",
       " ([0, 0, 1, 0, -0.7499999999999999, 0], 0),\n",
       " ([0, 0, -1, 0, 0, 0.010416666666666668], 0),\n",
       " ([0, 0, 1, 0, 0, -7.5], 0),\n",
       " ([0, 0, 0, -1, 0.0125, 0], 0),\n",
       " ([0, 0, 0, 1, -0.7499999999999999, 0], 0),\n",
       " ([0, 0, 0, -1, 0, 0.010416666666666668], 0),\n",
       " ([0, 0, 0, 1, 0, -7.5], 0),\n",
       " ([0, 0, 0, 0, -1, 0.8333333333333333], 0),\n",
       " ([0, 0, 0, 0, 1, -10.0], 0),\n",
       " ([-1, 200.0, 0, 0, 0, 0], 0),\n",
       " ([1, -100000.0, 0, 0, 0, 0], 0),\n",
       " ([-1, 0, 6.666666666666667, 0, 0, 0], 0),\n",
       " ([1, 0, -400.0, 0, 0, 0], 0),\n",
       " ([-1, 0, 0, 6.666666666666667, 0, 0], 0),\n",
       " ([1, 0, 0, -400.0, 0, 0], 0),\n",
       " ([-1, 0, 0, 0, 1.0, 0], 0),\n",
       " ([1, 0, 0, 0, -25.0, 0], 0),\n",
       " ([-1, 0, 0, 0, 0, 0.8333333333333334], 0),\n",
       " ([1, 0, 0, 0, 0, -250.0], 0),\n",
       " ([0, -1, 0.0003333333333333334, 0, 0, 0], 0),\n",
       " ([0, 1, -0.39999999999999997, 0, 0, 0], 0),\n",
       " ([0, -1, 0, 0.0003333333333333334, 0, 0], 0),\n",
       " ([0, 1, 0, -0.39999999999999997, 0, 0], 0),\n",
       " ([0, -1, 0, 0, 5e-05, 0], 0),\n",
       " ([0, 1, 0, 0, -0.016666666666666666, 0], 0),\n",
       " ([0, -1, 0, 0, 0, 4.166666666666667e-05], 0),\n",
       " ([0, 1, 0, 0, 0, -0.16666666666666669], 0),\n",
       " ([0, 0, -1, 1.0, 0, 0], 0),\n",
       " ([0, 0, 1, -5.0, 0, 0], 0),\n",
       " ([0, 0, -1, 0, 0.0125, 0], 0),\n",
       " ([0, 0, 1, 0, -0.7499999999999999, 0], 0),\n",
       " ([0, 0, -1, 0, 0, 0.010416666666666668], 0),\n",
       " ([0, 0, 1, 0, 0, -7.5], 0),\n",
       " ([0, 0, 0, -1, 0.0125, 0], 0),\n",
       " ([0, 0, 0, 1, -0.7499999999999999, 0], 0),\n",
       " ([0, 0, 0, -1, 0, 0.010416666666666668], 0),\n",
       " ([0, 0, 0, 1, 0, -7.5], 0),\n",
       " ([0, 0, 0, 0, -1, 0.8333333333333333], 0),\n",
       " ([0, 0, 0, 0, 1, -10.0], 0),\n",
       " ([-1, 200.0, 0, 0, 0, 0], 0),\n",
       " ([1, -100000.0, 0, 0, 0, 0], 0),\n",
       " ([-1, 0, 6.666666666666667, 0, 0, 0], 0),\n",
       " ([1, 0, -400.0, 0, 0, 0], 0),\n",
       " ([-1, 0, 0, 6.666666666666667, 0, 0], 0),\n",
       " ([1, 0, 0, -400.0, 0, 0], 0),\n",
       " ([-1, 0, 0, 0, 1.0, 0], 0),\n",
       " ([1, 0, 0, 0, -25.0, 0], 0),\n",
       " ([-1, 0, 0, 0, 0, 0.8333333333333334], 0),\n",
       " ([1, 0, 0, 0, 0, -250.0], 0),\n",
       " ([0, -1, 0.0003333333333333334, 0, 0, 0], 0),\n",
       " ([0, 1, -0.39999999999999997, 0, 0, 0], 0),\n",
       " ([0, -1, 0, 0.0003333333333333334, 0, 0], 0),\n",
       " ([0, 1, 0, -0.39999999999999997, 0, 0], 0),\n",
       " ([0, -1, 0, 0, 5e-05, 0], 0),\n",
       " ([0, 1, 0, 0, -0.016666666666666666, 0], 0),\n",
       " ([0, -1, 0, 0, 0, 4.166666666666667e-05], 0),\n",
       " ([0, 1, 0, 0, 0, -0.16666666666666669], 0),\n",
       " ([0, 0, -1, 1.0, 0, 0], 0),\n",
       " ([0, 0, 1, -5.0, 0, 0], 0),\n",
       " ([0, 0, -1, 0, 0.0125, 0], 0),\n",
       " ([0, 0, 1, 0, -0.7499999999999999, 0], 0),\n",
       " ([0, 0, -1, 0, 0, 0.010416666666666668], 0),\n",
       " ([0, 0, 1, 0, 0, -7.5], 0),\n",
       " ([0, 0, 0, -1, 0.0125, 0], 0),\n",
       " ([0, 0, 0, 1, -0.7499999999999999, 0], 0),\n",
       " ([0, 0, 0, -1, 0, 0.010416666666666668], 0),\n",
       " ([0, 0, 0, 1, 0, -7.5], 0),\n",
       " ([0, 0, 0, 0, -1, 0.8333333333333333], 0),\n",
       " ([0, 0, 0, 0, 1, -10.0], 0)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(A,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([1.8,0.14,0.07], device=device,dtype=torch.double)\n",
    "loss_fun = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.7121e-01, 3.2095e-04, 1.7992e-02, 1.0920e-02, 1.2947e-01, 8.6651e-02],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "26, 0.029818016497\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999, 0.000176665784\r"
     ]
    }
   ],
   "source": [
    "# init guess\n",
    "guess = torch.randn((6),dtype=torch.double)\n",
    "guess = network.bn0.running_mean[:6].clone().detach()\n",
    "\n",
    "initial_current_density = 3\n",
    "guess[0] = initial_current_density\n",
    "\n",
    "# initially project to ensure all values make sense and the continuous transformations make sense  as well\n",
    "magnet_params = torch.tensor(project_to_poly2(guess.detach().cpu().numpy())).unsqueeze(0).to(device).requires_grad_(True)\n",
    "\n",
    "lr = 1e-1\n",
    "lr_tensor = network.bn0.running_mean[:6].clone().detach() * lr\n",
    "print(lr_tensor)\n",
    "network.eval()\n",
    "\n",
    "n_steps = 1000\n",
    "\n",
    "for step in range(n_steps):\n",
    "    if magnet_params.grad is not None:\n",
    "        magnet_params.grad.zero_()\n",
    "    for layer in network.parameters():\n",
    "        if layer.grad is not None:\n",
    "            layer.grad.zero_()\n",
    "\n",
    "    pred = network(magnet_params)\n",
    "    #print(pred)\n",
    "    loss = loss_fun(pred,target)\n",
    "    #print(loss)\n",
    "\n",
    "    print(f\"{step}, {loss.detach().cpu().numpy():.12f}\",end=\"\\r\")\n",
    "    loss.backward()\n",
    "    with torch.no_grad():        \n",
    "        magnet_params = magnet_params - lr_tensor * magnet_params.grad\n",
    "        proj_result = project_to_poly2(magnet_params.squeeze().detach().cpu().numpy())\n",
    "        if (proj_result is None):\n",
    "            magnet_params = torch.tensor(magnet_params).requires_grad_(True)\n",
    "        else:        \n",
    "            magnet_params = torch.tensor(proj_result).unsqueeze(0).to(device).requires_grad_(True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.2505, 0.0100, 0.1642, 0.1642, 1.9992, 2.2987]], device='cuda:0',\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magnet_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import femmcreator\n",
    "import magnetdesigner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2505109002683796 0.010006523443922517 0.16416221120380337 0.1641613714426864 1.9991632692079533 2.298656318300901\n"
     ]
    }
   ],
   "source": [
    "magnet_params_np = magnet_params.squeeze().detach().cpu().numpy()\n",
    "\n",
    "print(*list(*(magnet_params.detach().cpu().numpy())))\n",
    "#['maxCurrentDensity', 'fieldTolerance', 'aper_x', 'aper_y', 'B_design', 'B_real']\n",
    "dipole = magnetdesigner.designer.get_Dipole(magnet_params_np[4], magnet_params_np[1], 5000, 1e-3, 1e-3, aper_x=magnet_params_np[2], aper_y=magnet_params_np[3], maxCurrentDensity=magnet_params_np[0], B_real=magnet_params_np[5])\n",
    "\n",
    "femm = femmcreator.FEMM()\n",
    "femm.Build(dipole.get_femminput)\n",
    "femm.CreateFEMM('dipole_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = dataset_train.dataframe[(dataset_train.dataframe[\"yoke_x\"]==1.4824975) & \n",
    "                        (dataset_train.dataframe[\"yoke_y\"]==0.783038) &\n",
    "                        (dataset_train.dataframe[\"aper_x\"]==0.3) &\n",
    "                        (dataset_train.dataframe[\"aper_y\"]==0.075)][important_cols_order + [\"B0\",\"gfr_x_1e-4\",\"gfr_y_1e-4\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_591666/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxCurrentDensity</th>\n",
       "      <th>fieldTolerance</th>\n",
       "      <th>aper_x</th>\n",
       "      <th>aper_y</th>\n",
       "      <th>B_design</th>\n",
       "      <th>B_real</th>\n",
       "      <th>B0</th>\n",
       "      <th>gfr_x_1e-4</th>\n",
       "      <th>gfr_y_1e-4</th>\n",
       "      <th>pred_B0</th>\n",
       "      <th>pred_gfr_x</th>\n",
       "      <th>pred_gfr_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49826</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.358991</td>\n",
       "      <td>0.342158</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.343749</td>\n",
       "      <td>0.366186</td>\n",
       "      <td>0.076367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49828</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.598375</td>\n",
       "      <td>0.339483</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.564004</td>\n",
       "      <td>0.341917</td>\n",
       "      <td>0.068916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49832</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.061886</td>\n",
       "      <td>0.298884</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.004513</td>\n",
       "      <td>0.293379</td>\n",
       "      <td>0.054016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49827</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.478710</td>\n",
       "      <td>0.341072</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.453877</td>\n",
       "      <td>0.354051</td>\n",
       "      <td>0.072642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49829</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.717982</td>\n",
       "      <td>0.337774</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.674131</td>\n",
       "      <td>0.329782</td>\n",
       "      <td>0.065191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49835</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.296217</td>\n",
       "      <td>0.169453</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.334895</td>\n",
       "      <td>0.256976</td>\n",
       "      <td>0.042840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49830</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.836991</td>\n",
       "      <td>0.335543</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.784259</td>\n",
       "      <td>0.317648</td>\n",
       "      <td>0.061466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49824</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.119470</td>\n",
       "      <td>0.342736</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.123495</td>\n",
       "      <td>0.390455</td>\n",
       "      <td>0.083817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49834</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.233042</td>\n",
       "      <td>0.204116</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.224768</td>\n",
       "      <td>0.269110</td>\n",
       "      <td>0.046565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49825</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.239236</td>\n",
       "      <td>0.342575</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.233622</td>\n",
       "      <td>0.378320</td>\n",
       "      <td>0.080092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       maxCurrentDensity  fieldTolerance  aper_x  aper_y  B_design  B_real  \\\n",
       "49826                2.0            0.01     0.3   0.075       1.2    0.36   \n",
       "49828                2.0            0.01     0.3   0.075       1.2    0.60   \n",
       "49832                2.0            0.01     0.3   0.075       1.2    1.08   \n",
       "49827                2.0            0.01     0.3   0.075       1.2    0.48   \n",
       "49829                2.0            0.01     0.3   0.075       1.2    0.72   \n",
       "49835                2.0            0.01     0.3   0.075       1.2    1.44   \n",
       "49830                2.0            0.01     0.3   0.075       1.2    0.84   \n",
       "49824                2.0            0.01     0.3   0.075       1.2    0.12   \n",
       "49834                2.0            0.01     0.3   0.075       1.2    1.32   \n",
       "49825                2.0            0.01     0.3   0.075       1.2    0.24   \n",
       "\n",
       "             B0  gfr_x_1e-4  gfr_y_1e-4   pred_B0  pred_gfr_x  pred_gfr_y  \n",
       "49826  0.358991    0.342158        0.06  0.343749    0.366186    0.076367  \n",
       "49828  0.598375    0.339483        0.06  0.564004    0.341917    0.068916  \n",
       "49832  1.061886    0.298884        0.06  1.004513    0.293379    0.054016  \n",
       "49827  0.478710    0.341072        0.06  0.453877    0.354051    0.072642  \n",
       "49829  0.717982    0.337774        0.06  0.674131    0.329782    0.065191  \n",
       "49835  1.296217    0.169453        0.06  1.334895    0.256976    0.042840  \n",
       "49830  0.836991    0.335543        0.06  0.784259    0.317648    0.061466  \n",
       "49824  0.119470    0.342736        0.06  0.123495    0.390455    0.083817  \n",
       "49834  1.233042    0.204116        0.06  1.224768    0.269110    0.046565  \n",
       "49825  0.239236    0.342575        0.06  0.233622    0.378320    0.080092  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.eval()\n",
    "\n",
    "def fun(r,i):\n",
    "    inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
    "    pred = network(inp).cpu().detach()[0,i].item()\n",
    "    return pred\n",
    "\n",
    "group = group.assign(pred_B0=group.apply( lambda r: fun(r,0) ,axis=1))\n",
    "group = group.assign(pred_gfr_x=group.apply( lambda r: fun(r,1) ,axis=1))\n",
    "group = group.assign(pred_gfr_y=group.apply( lambda r: fun(r,2) ,axis=1))\n",
    "\n",
    "group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
