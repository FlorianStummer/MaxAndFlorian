{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import data.datasets as dataSource\n",
    "import torch.utils.data as tdata\n",
    "import numpy as np\n",
    "import scipy.constants as _scipy_constants\n",
    "\n",
    "import cvxpy as cp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B_design', 'fieldTolerance', 'maxCurrentDensity', 'aper_x', 'aper_y', 'B_real']\n",
      "['maxCurrentDensity', 'fieldTolerance', 'aper_x', 'aper_y', 'B_design', 'B_real']\n"
     ]
    }
   ],
   "source": [
    "dataset_train, dataset_val = dataSource.Dipole_H_train, dataSource.Dipole_H_val\n",
    "batch_size = 64\n",
    "important_cols = [\"B_design\", \"fieldTolerance\", \"maxCurrentDensity\", \"aper_x\", \"aper_y\", \"B_real\"]\n",
    "important_cols_order = sorted(important_cols,key=lambda c: dataset_train.input_columns.index(c))\n",
    "\n",
    "print(important_cols)\n",
    "print(important_cols_order)\n",
    "\n",
    "input_mask = [True if col in important_cols else False for col in dataset_train.input_columns]\n",
    "train_loader, val_loader = tdata.DataLoader(dataset_train,batch_size), tdata.DataLoader(dataset_val,batch_size)\n",
    "\n",
    "target_index_dict = {col:i for i,col in enumerate(dataset_train.target_columns)}\n",
    "target_cols = [\"B0\",\"gfr_x_1e-3\",\"gfr_y_1e-3\"]\n",
    "output_mask = [True if col in target_cols else False for col in dataset_train.target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2925552815282366"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.dataframe[\"B_design\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "oid = {key : important_cols.index(key) for key in important_cols_order}\n",
    "\n",
    "def get_dipole_continuous(x: torch.Tensor):\n",
    "    # x.shape = (b,6) with batchDim b and 6 \"actual\" inputs 'important cols'\n",
    "    aper_x = x[:,oid[\"aper_x\"]]\n",
    "    aper_y = x[:,oid[\"aper_y\"]]\n",
    "    maxCurrentDensity = x[:,oid[\"maxCurrentDensity\"]]\n",
    "    fieldTolerance = x[:,oid[\"fieldTolerance\"]]\n",
    "    B_design = x[:,oid[\"B_design\"]]\n",
    "    B_real = x[:,oid[\"B_real\"]]\n",
    "\n",
    "    gfr_x = aper_x - 0.015\n",
    "    gfr_y = aper_y - 0.015\n",
    "    aper_x_poleoverhang = aper_x * 0.5 * (-0.36 * torch.log(fieldTolerance) - 0.90)\n",
    "    aper_x_tapering = aper_x_poleoverhang * 0.1\n",
    "    aper_y_distFromCoil = aper_y * 0.1\n",
    "    B_max = B_design * (1 + 20 * 0.01)\n",
    "    totalCurrent = B_real * aper_y / (2 * _scipy_constants.mu_0)\n",
    "    totalCurrentMax = B_max * aper_y / (2 * _scipy_constants.mu_0)\n",
    "\n",
    "    # windings and related properties dont work exactly, as the ceil function is not continuous\n",
    "    # nevertheless, the continuous approximations could still be useful for the network\n",
    "    #windings_cont = totalCurrentMax / maxCurrent\n",
    "    \n",
    "    w = aper_x + 2 * aper_x_poleoverhang\n",
    "    w_leg = 0*5 * (w + 2 * aper_y) * B_max / 2.15\n",
    "\n",
    "    minCoilArea = totalCurrentMax / (maxCurrentDensity * (75 * 0.01)) / 1e6\n",
    "\n",
    "    coil_width = torch.sqrt(minCoilArea * 2)\n",
    "    coil_height = minCoilArea / coil_width\n",
    "\n",
    "    yoke_x = w + 2 * (aper_x_tapering + w_leg + coil_width)\n",
    "    yoke_y = aper_y + 2 * (aper_y_distFromCoil + w_leg + coil_height)\n",
    "\n",
    "    stack = torch.cat([\n",
    "        x,\n",
    "        gfr_x.unsqueeze(1),\n",
    "        gfr_y.unsqueeze(1),\n",
    "        aper_x_poleoverhang.unsqueeze(1),\n",
    "        aper_x_tapering.unsqueeze(1),\n",
    "        aper_y_distFromCoil.unsqueeze(1),\n",
    "        B_max.unsqueeze(1),\n",
    "        totalCurrent.unsqueeze(1),\n",
    "        totalCurrentMax.unsqueeze(1),\n",
    "        w.unsqueeze(1),\n",
    "        w_leg.unsqueeze(1),\n",
    "        minCoilArea.unsqueeze(1),\n",
    "        coil_width.unsqueeze(1),\n",
    "        coil_height.unsqueeze(1),\n",
    "        yoke_x.unsqueeze(1),\n",
    "        yoke_y.unsqueeze(1),\n",
    "        ],dim=1)\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRegNet(nn.Module):\n",
    "    def __init__(self,h_size=32):\n",
    "        super().__init__()\n",
    "        self.bn0 = nn.BatchNorm1d(len(important_cols)+15, dtype=torch.double)\n",
    "        self.fc1 = nn.Linear(len(important_cols)+15,h_size, dtype=torch.double)\n",
    "        self.nl1 = nn.LeakyReLU()\n",
    "        self.bn1 = nn.BatchNorm1d(h_size, dtype=torch.double)\n",
    "        #self.do1 = nn.Dropout1d(0.5)\n",
    "        self.fc2 = nn.Linear(h_size,h_size, dtype=torch.double)\n",
    "        self.nl2 = nn.LeakyReLU()\n",
    "        self.bn2 = nn.BatchNorm1d(h_size, dtype=torch.double)\n",
    "        #self.do2 = nn.Dropout1d()\n",
    "        self.fc3 = nn.Linear(h_size,3, dtype=torch.double)\n",
    "    def forward(self,x):\n",
    "        x = get_dipole_continuous(x)\n",
    "        x = self.bn0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.nl1(x)\n",
    "        x = self.bn1(x)\n",
    "        #x = self.do1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.nl2(x)\n",
    "        x = self.bn2(x)\n",
    "        #x = self.do2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "network = MyRegNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mask_df = dataset_train.dataframe[[\"B0\",\"gfr_x_1e-4\",\"gfr_y_1e-4\"]].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 tensor(11.1147) tensor(2.9856)5)\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m network\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      8\u001b[0m loss_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     10\u001b[0m     selected_x \u001b[38;5;241m=\u001b[39m x[:,input_mask]\u001b[38;5;241m.\u001b[39mdouble()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m     selected_y \u001b[38;5;241m=\u001b[39m y[:,output_mask]\u001b[38;5;241m.\u001b[39mdouble()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/florian/MaxAndFlorian/src/final_sprint/data/datasets.py:34\u001b[0m, in \u001b[0;36m_MyDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 34\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     35\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets\u001b[38;5;241m.\u001b[39miloc[idx]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs, target\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1192\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1191\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1755\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m-> 1755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3990\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3988\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced_from_mgr(new_mgr, axes\u001b[38;5;241m=\u001b[39mnew_mgr\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   3989\u001b[0m result\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex[i]\n\u001b[0;32m-> 3990\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__finalize__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3991\u001b[0m result\u001b[38;5;241m.\u001b[39m_set_is_copy(\u001b[38;5;28mself\u001b[39m, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   3992\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:6256\u001b[0m, in \u001b[0;36mNDFrame.__finalize__\u001b[0;34m(self, other, method, **kwargs)\u001b[0m\n\u001b[1;32m   6249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mattrs:\n\u001b[1;32m   6250\u001b[0m     \u001b[38;5;66;03m# We want attrs propagation to have minimal performance\u001b[39;00m\n\u001b[1;32m   6251\u001b[0m     \u001b[38;5;66;03m# impact if attrs are not used; i.e. attrs is an empty dict.\u001b[39;00m\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;66;03m# One could make the deepcopy unconditionally, but a deepcopy\u001b[39;00m\n\u001b[1;32m   6253\u001b[0m     \u001b[38;5;66;03m# of an empty dict is 50x more expensive than the empty check.\u001b[39;00m\n\u001b[1;32m   6254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs \u001b[38;5;241m=\u001b[39m deepcopy(other\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[0;32m-> 6256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mallows_duplicate_labels \u001b[38;5;241m=\u001b[39m \u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallows_duplicate_labels\u001b[49m\n\u001b[1;32m   6257\u001b[0m \u001b[38;5;66;03m# For subclasses using _metadata.\u001b[39;00m\n\u001b[1;32m   6258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(other\u001b[38;5;241m.\u001b[39m_metadata):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/flags.py:55\u001b[0m, in \u001b[0;36mFlags.allows_duplicate_labels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allows_duplicate_labels \u001b[38;5;241m=\u001b[39m allows_duplicate_labels\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(obj)\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mallows_duplicate_labels\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    Whether this object allows duplicate labels.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    a        [0, 1]\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allows_duplicate_labels\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "lr = 1e-4\n",
    "optim = torch.optim.Adam(network.parameters(), lr)\n",
    "loss_fun = nn.MSELoss()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    network.train()\n",
    "    loss_list = []\n",
    "    for x,y in train_loader:\n",
    "        selected_x = x[:,input_mask].double().to(device)\n",
    "        selected_y = y[:,output_mask].double().to(device)\n",
    "        pred = network(selected_x)\n",
    "\n",
    "        loss_mask = (torch.tensor(list(loss_mask_df))* torch.tensor([10,1,1])).repeat((x.shape[0],1)).to(device)\n",
    "        loss = loss_fun(pred * loss_mask,selected_y * loss_mask)\n",
    "        loss_list.append(loss.detach().item())\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    epoch_train_loss = torch.tensor(loss_list).mean()\n",
    "\n",
    "    network.eval()\n",
    "    loss_list = []\n",
    "    for x,y in val_loader:\n",
    "        selected_x = x[:,input_mask].double().to(device)\n",
    "        selected_y = y[:,output_mask].double().to(device)\n",
    "        pred = network(selected_x)\n",
    "\n",
    "        loss_mask = (torch.tensor(list(loss_mask_df))* torch.tensor([10,1,1])).repeat((x.shape[0],1)).to(device)\n",
    "        loss = loss_fun(pred * loss_mask,selected_y * loss_mask)\n",
    "        loss_list.append(loss.detach().item())\n",
    "    epoch_val_loss = torch.tensor(loss_list).mean()\n",
    "    print(epoch,epoch_train_loss,epoch_val_loss,end=\"\\r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), \"network_design_params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "network = MyRegNet().to(device)\n",
    "network.load_state_dict(torch.load(\"network_design_params\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = []\n",
    "b = []\n",
    "\n",
    "def onehot(name, neg):\n",
    "    out = [0] * len(important_cols_order)\n",
    "    out[important_cols_order.index(name)] = -1 if neg else 1\n",
    "    return out\n",
    "\n",
    "for name in important_cols_order:\n",
    "    # constraints for minima: x > a --> -x < -a\n",
    "    A.append(onehot(name,True))\n",
    "    b.append(-dataset_train.input_mins[name])\n",
    "    \n",
    "    # constraints for maxima: x < a\n",
    "    A.append(onehot(name,False))\n",
    "    b.append(dataset_train.input_maxs[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_rel = []\n",
    "b_rel = []\n",
    "\n",
    "# ['maxCurrentDensity', 'fieldTolerance', 'aper_x', 'aper_y', 'B_design', 'B_real']\n",
    "\n",
    "# aper_x > aper_y --> aper_y - aper_x < 0\n",
    "A_rel.append([0, 0, -1, 1, 0, 0])\n",
    "b_rel.append(0)\n",
    "\n",
    "# aper_x < 5 * aper_y --> aper_x - 5 * aper_y < 0\n",
    "A_rel.append([0, 0, 1, -5, 0, 0])\n",
    "b_rel.append(0)\n",
    "\n",
    "# 1.2 * B_design > B_real --> B_real - 1.2 * B_design < 0\n",
    "A_rel.append([0, 0, 0, 0, -1.2, 1])\n",
    "b_rel.append(0)\n",
    "\n",
    "\n",
    "A = A + A_rel\n",
    "b = b + b_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxCurrentDensity fieldTolerance 200.002 99999.0 --> [-1, 200.002, 0, 0, 0, 0] < 0 and [1, -99999.0, 0, 0, 0, 0] < 0\n",
      "maxCurrentDensity aper_x 6.666733333333334 399.99600000000004 --> [-1, 0, 6.666733333333334, 0, 0, 0] < 0 and [1, 0, -399.99600000000004, 0, 0, 0] < 0\n",
      "maxCurrentDensity aper_y 6.666733333333334 399.99600000000004 --> [-1, 0, 0, 6.666733333333334, 0, 0] < 0 and [1, 0, 0, -399.99600000000004, 0, 0] < 0\n",
      "maxCurrentDensity B_design 1.00001 24.999750000000002 --> [-1, 0, 0, 0, 1.00001, 0] < 0 and [1, 0, 0, 0, -24.999750000000002, 0] < 0\n",
      "maxCurrentDensity B_real 0.8333416666666668 249.9975 --> [-1, 0, 0, 0, 0, 0.8333416666666668] < 0 and [1, 0, 0, 0, 0, -249.9975] < 0\n",
      "fieldTolerance aper_x 0.00033333666666666674 0.39999599999999996 --> [0, -1, 0.00033333666666666674, 0, 0, 0] < 0 and [0, 1, -0.39999599999999996, 0, 0, 0] < 0\n",
      "fieldTolerance aper_y 0.00033333666666666674 0.39999599999999996 --> [0, -1, 0, 0.00033333666666666674, 0, 0] < 0 and [0, 1, 0, -0.39999599999999996, 0, 0] < 0\n",
      "fieldTolerance B_design 5.0000500000000003e-05 0.0166665 --> [0, -1, 0, 0, 5.0000500000000003e-05, 0] < 0 and [0, 1, 0, 0, -0.0166665, 0] < 0\n",
      "fieldTolerance B_real 4.166708333333334e-05 0.16666500000000004 --> [0, -1, 0, 0, 0, 4.166708333333334e-05] < 0 and [0, 1, 0, 0, 0, -0.16666500000000004] < 0\n",
      "aper_x aper_y 1.00001 4.99995 --> [0, 0, -1, 1.00001, 0, 0] < 0 and [0, 0, 1, -4.99995, 0, 0] < 0\n",
      "aper_x B_design 0.012500125 0.7499925 --> [0, 0, -1, 0, 0.012500125, 0] < 0 and [0, 0, 1, 0, -0.7499925, 0] < 0\n",
      "aper_x B_real 0.010416770833333335 7.499925 --> [0, 0, -1, 0, 0, 0.010416770833333335] < 0 and [0, 0, 1, 0, 0, -7.499925] < 0\n",
      "aper_y B_design 0.012500125 0.7499925 --> [0, 0, 0, -1, 0.012500125, 0] < 0 and [0, 0, 0, 1, -0.7499925, 0] < 0\n",
      "aper_y B_real 0.010416770833333335 7.499925 --> [0, 0, 0, -1, 0, 0.010416770833333335] < 0 and [0, 0, 0, 1, 0, -7.499925] < 0\n",
      "B_design B_real 0.8333416666666666 9.9999 --> [0, 0, 0, 0, -1, 0.8333416666666666] < 0 and [0, 0, 0, 0, 1, -9.9999] < 0\n"
     ]
    }
   ],
   "source": [
    "# ratio constraints \n",
    "# compute min and max ratio for every pair of inputs and ensure the ratio is in that range with two linear constraints\n",
    "# e.g. min < a/b < max -->  min * b - a < 0 and a - max * b < 0\n",
    "# with slack. min * (1+e) < a/b < max * (1-e) -->  (min (1+ e)) * b - a < 0 and a - (max*(1-e)) * b < 0\n",
    "\n",
    "A_rat = []\n",
    "b_rat = []\n",
    "epsilon = 1e-5\n",
    "\n",
    "for i in range(len(important_cols_order)-1):\n",
    "    for j in range(i+1,len(important_cols_order)):\n",
    "        quantity_1 = important_cols_order[i]\n",
    "        quantity_2 = important_cols_order[j]\n",
    "\n",
    "        # ratio = column i/ colimn j\n",
    "        ratio_df = dataset_train.dataframe.assign(ratio=dataset_train.dataframe.apply(lambda r: r[quantity_1] / r[quantity_2], axis=1))\n",
    "\n",
    "        minimum = ratio_df[\"ratio\"].min() \n",
    "        maximum = ratio_df[\"ratio\"].max()\n",
    "\n",
    "        minimum *= 1+epsilon\n",
    "        maximum *= 1-epsilon\n",
    "\n",
    "        # min * j - i < 0\n",
    "        min_row = [0]*6\n",
    "        min_row[i] = -1\n",
    "        min_row[j] = minimum\n",
    "        A_rat.append(min_row)\n",
    "        b_rat.append(0)\n",
    "\n",
    "        #i - max * k < 0\n",
    "        max_row = [0]*6\n",
    "        max_row[i] = 1\n",
    "        max_row[j] = -maximum\n",
    "        A_rat.append(max_row)\n",
    "        b_rat.append(0)\n",
    "\n",
    "        print(quantity_1,quantity_2,minimum,maximum, \"-->\", min_row,\"< 0 and\", max_row,\"< 0\")\n",
    "\n",
    "\n",
    "A = A + A_rat\n",
    "b = b + b_rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 1. ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def project_to_poly2(x, A_mat=A, b_vec = b):\n",
    "    # Define decision variable\n",
    "    p = cp.Variable(len(x))\n",
    "    # Define objective function\n",
    "    objective = cp.Minimize(cp.sum_squares(p - x))\n",
    "\n",
    "    A_mat_dynamic = A_mat[:]\n",
    "    b_vec_dynamic = b_vec[:]\n",
    "\n",
    "\n",
    "    # Define constraints\n",
    "    constraints = [np.array(A_mat) @ p <= np.array(b_vec)]\n",
    "\n",
    "    # Solve the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "\n",
    "\n",
    "    # Optimal solution\n",
    "    closest_point = p.value\n",
    "    return closest_point\n",
    "\n",
    "A_test = [[0,1],[1,0]]\n",
    "b_test = [1,1]\n",
    "project_to_poly2([0.5,1.2],A_test,b_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([-1, 0, 0, 0, 0, 0], -2.0),\n",
       " ([1, 0, 0, 0, 0, 0], 10.0),\n",
       " ([0, -1, 0, 0, 0, 0], -0.0001),\n",
       " ([0, 1, 0, 0, 0, 0], 0.01),\n",
       " ([0, 0, -1, 0, 0, 0], -0.025),\n",
       " ([0, 0, 1, 0, 0, 0], 0.3),\n",
       " ([0, 0, 0, -1, 0, 0], -0.025),\n",
       " ([0, 0, 0, 1, 0, 0], 0.3),\n",
       " ([0, 0, 0, 0, -1, 0], -0.4),\n",
       " ([0, 0, 0, 0, 1, 0], 2.0),\n",
       " ([0, 0, 0, 0, 0, -1], -0.04),\n",
       " ([0, 0, 0, 0, 0, 1], 2.4),\n",
       " ([0, 0, -1, 1, 0, 0], 0),\n",
       " ([0, 0, 1, -5, 0, 0], 0),\n",
       " ([0, 0, 0, 0, -1.2, 1], 0),\n",
       " ([-1, 200.002, 0, 0, 0, 0], 0),\n",
       " ([1, -99999.0, 0, 0, 0, 0], 0),\n",
       " ([-1, 0, 6.666733333333334, 0, 0, 0], 0),\n",
       " ([1, 0, -399.99600000000004, 0, 0, 0], 0),\n",
       " ([-1, 0, 0, 6.666733333333334, 0, 0], 0),\n",
       " ([1, 0, 0, -399.99600000000004, 0, 0], 0),\n",
       " ([-1, 0, 0, 0, 1.00001, 0], 0),\n",
       " ([1, 0, 0, 0, -24.999750000000002, 0], 0),\n",
       " ([-1, 0, 0, 0, 0, 0.8333416666666668], 0),\n",
       " ([1, 0, 0, 0, 0, -249.9975], 0),\n",
       " ([0, -1, 0.00033333666666666674, 0, 0, 0], 0),\n",
       " ([0, 1, -0.39999599999999996, 0, 0, 0], 0),\n",
       " ([0, -1, 0, 0.00033333666666666674, 0, 0], 0),\n",
       " ([0, 1, 0, -0.39999599999999996, 0, 0], 0),\n",
       " ([0, -1, 0, 0, 5.0000500000000003e-05, 0], 0),\n",
       " ([0, 1, 0, 0, -0.0166665, 0], 0),\n",
       " ([0, -1, 0, 0, 0, 4.166708333333334e-05], 0),\n",
       " ([0, 1, 0, 0, 0, -0.16666500000000004], 0),\n",
       " ([0, 0, -1, 1.00001, 0, 0], 0),\n",
       " ([0, 0, 1, -4.99995, 0, 0], 0),\n",
       " ([0, 0, -1, 0, 0.012500125, 0], 0),\n",
       " ([0, 0, 1, 0, -0.7499925, 0], 0),\n",
       " ([0, 0, -1, 0, 0, 0.010416770833333335], 0),\n",
       " ([0, 0, 1, 0, 0, -7.499925], 0),\n",
       " ([0, 0, 0, -1, 0.012500125, 0], 0),\n",
       " ([0, 0, 0, 1, -0.7499925, 0], 0),\n",
       " ([0, 0, 0, -1, 0, 0.010416770833333335], 0),\n",
       " ([0, 0, 0, 1, 0, -7.499925], 0),\n",
       " ([0, 0, 0, 0, -1, 0.8333416666666666], 0),\n",
       " ([0, 0, 0, 0, 1, -9.9999], 0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(A,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([1.8,0.09,0.05], device=device,dtype=torch.double)\n",
    "loss_fun = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5388e-01, 3.0386e-04, 1.7841e-02, 1.0638e-02, 1.3079e-01, 8.6227e-02],\n",
      "       device='cuda:0', dtype=torch.float64)\n",
      "5, 0.194509406554\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21, 0.094339659541\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([1, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999, 0.000079862405\r"
     ]
    }
   ],
   "source": [
    "# init guess\n",
    "guess = torch.randn((6),dtype=torch.double)\n",
    "guess = network.bn0.running_mean[:6].clone().detach()\n",
    "\n",
    "initial_current_density = 3\n",
    "guess[0] = initial_current_density\n",
    "\n",
    "# initially project to ensure all values make sense and the continuous transformations make sense  as well\n",
    "magnet_params = torch.tensor(project_to_poly2(guess.detach().cpu().numpy())).unsqueeze(0).to(device).requires_grad_(True)\n",
    "\n",
    "lr = 1e-1\n",
    "lr_tensor = network.bn0.running_mean[:6].clone().detach() * lr\n",
    "print(lr_tensor)\n",
    "network.eval()\n",
    "\n",
    "n_steps = 1000\n",
    "\n",
    "for step in range(n_steps):\n",
    "    if magnet_params.grad is not None:\n",
    "        magnet_params.grad.zero_()\n",
    "    for layer in network.parameters():\n",
    "        if layer.grad is not None:\n",
    "            layer.grad.zero_()\n",
    "\n",
    "    pred = network(magnet_params)\n",
    "    #print(pred)\n",
    "    loss = loss_fun(pred,target)\n",
    "    #print(loss)\n",
    "\n",
    "    print(f\"{step}, {loss.detach().cpu().numpy():.12f}\",end=\"\\r\")\n",
    "    loss.backward()\n",
    "    with torch.no_grad():        \n",
    "        magnet_params = magnet_params - lr_tensor * magnet_params.grad\n",
    "        proj_result = project_to_poly2(magnet_params.squeeze().detach().cpu().numpy())\n",
    "        if (proj_result is None):\n",
    "            magnet_params = torch.tensor(magnet_params).requires_grad_(True)\n",
    "        else:        \n",
    "            magnet_params = torch.tensor(proj_result).unsqueeze(0).to(device).requires_grad_(True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1314, 0.0100, 0.2843, 0.0569, 1.8236, 2.0215]], device='cuda:0',\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magnet_params\n",
    "magnet_params = torch.tensor(project_to_poly2(magnet_params.squeeze().detach().cpu().numpy())).unsqueeze(0).to(device).requires_grad_(True)\n",
    "magnet_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import femmcreator\n",
    "import magnetdesigner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1314257491354187 0.00997080298317767 0.28431794779911884 0.05686624195408862 1.823586696080743 2.0215152612383305\n"
     ]
    }
   ],
   "source": [
    "magnet_params_np = magnet_params.squeeze().detach().cpu().numpy()\n",
    "\n",
    "print(*list(*(magnet_params.detach().cpu().numpy())))\n",
    "#['maxCurrentDensity', 'fieldTolerance', 'aper_x', 'aper_y', 'B_design', 'B_real']\n",
    "dipole = magnetdesigner.designer.get_Dipole(magnet_params_np[4], magnet_params_np[1], 5000, 1e-3, 1e-3, aper_x=magnet_params_np[2], aper_y=magnet_params_np[3], maxCurrentDensity=magnet_params_np[0], B_real=magnet_params_np[5])\n",
    "\n",
    "femm = femmcreator.FEMM()\n",
    "femm.Build(dipole.get_femminput)\n",
    "femm.CreateFEMM('dipole_2_low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = dataset_train.dataframe[(dataset_train.dataframe[\"yoke_x\"]==1.4824975) & \n",
    "                        (dataset_train.dataframe[\"yoke_y\"]==0.783038) &\n",
    "                        (dataset_train.dataframe[\"aper_x\"]==0.3) &\n",
    "                        (dataset_train.dataframe[\"aper_y\"]==0.075)][important_cols_order + [\"B0\",\"gfr_x_1e-4\",\"gfr_y_1e-4\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
      "/tmp/ipykernel_902309/1237417832.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxCurrentDensity</th>\n",
       "      <th>fieldTolerance</th>\n",
       "      <th>aper_x</th>\n",
       "      <th>aper_y</th>\n",
       "      <th>B_design</th>\n",
       "      <th>B_real</th>\n",
       "      <th>B0</th>\n",
       "      <th>gfr_x_1e-4</th>\n",
       "      <th>gfr_y_1e-4</th>\n",
       "      <th>pred_B0</th>\n",
       "      <th>pred_gfr_x</th>\n",
       "      <th>pred_gfr_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49826</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.358991</td>\n",
       "      <td>0.342158</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.378219</td>\n",
       "      <td>0.246260</td>\n",
       "      <td>0.062187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49828</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.598375</td>\n",
       "      <td>0.339483</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.607107</td>\n",
       "      <td>0.263063</td>\n",
       "      <td>0.065162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49832</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.061886</td>\n",
       "      <td>0.298884</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.023091</td>\n",
       "      <td>0.322501</td>\n",
       "      <td>0.086554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49827</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.478710</td>\n",
       "      <td>0.341072</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.495548</td>\n",
       "      <td>0.237289</td>\n",
       "      <td>0.057190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49829</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.717982</td>\n",
       "      <td>0.337774</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.735511</td>\n",
       "      <td>0.304668</td>\n",
       "      <td>0.073545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49835</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.296217</td>\n",
       "      <td>0.169453</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.288779</td>\n",
       "      <td>0.195491</td>\n",
       "      <td>0.078254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49830</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.836991</td>\n",
       "      <td>0.335543</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.817226</td>\n",
       "      <td>0.316204</td>\n",
       "      <td>0.074684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49824</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.119470</td>\n",
       "      <td>0.342736</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.147658</td>\n",
       "      <td>0.254806</td>\n",
       "      <td>0.073315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49834</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.233042</td>\n",
       "      <td>0.204116</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.201850</td>\n",
       "      <td>0.267996</td>\n",
       "      <td>0.089781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49825</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.239236</td>\n",
       "      <td>0.342575</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.263762</td>\n",
       "      <td>0.250561</td>\n",
       "      <td>0.067625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       maxCurrentDensity  fieldTolerance  aper_x  aper_y  B_design  B_real  \\\n",
       "49826                2.0            0.01     0.3   0.075       1.2    0.36   \n",
       "49828                2.0            0.01     0.3   0.075       1.2    0.60   \n",
       "49832                2.0            0.01     0.3   0.075       1.2    1.08   \n",
       "49827                2.0            0.01     0.3   0.075       1.2    0.48   \n",
       "49829                2.0            0.01     0.3   0.075       1.2    0.72   \n",
       "49835                2.0            0.01     0.3   0.075       1.2    1.44   \n",
       "49830                2.0            0.01     0.3   0.075       1.2    0.84   \n",
       "49824                2.0            0.01     0.3   0.075       1.2    0.12   \n",
       "49834                2.0            0.01     0.3   0.075       1.2    1.32   \n",
       "49825                2.0            0.01     0.3   0.075       1.2    0.24   \n",
       "\n",
       "             B0  gfr_x_1e-4  gfr_y_1e-4   pred_B0  pred_gfr_x  pred_gfr_y  \n",
       "49826  0.358991    0.342158        0.06  0.378219    0.246260    0.062187  \n",
       "49828  0.598375    0.339483        0.06  0.607107    0.263063    0.065162  \n",
       "49832  1.061886    0.298884        0.06  1.023091    0.322501    0.086554  \n",
       "49827  0.478710    0.341072        0.06  0.495548    0.237289    0.057190  \n",
       "49829  0.717982    0.337774        0.06  0.735511    0.304668    0.073545  \n",
       "49835  1.296217    0.169453        0.06  1.288779    0.195491    0.078254  \n",
       "49830  0.836991    0.335543        0.06  0.817226    0.316204    0.074684  \n",
       "49824  0.119470    0.342736        0.06  0.147658    0.254806    0.073315  \n",
       "49834  1.233042    0.204116        0.06  1.201850    0.267996    0.089781  \n",
       "49825  0.239236    0.342575        0.06  0.263762    0.250561    0.067625  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.eval()\n",
    "\n",
    "def fun(r,i):\n",
    "    inp = torch.tensor(r[important_cols_order],device=device,dtype=torch.double).unsqueeze(0)\n",
    "    pred = network(inp).cpu().detach()[0,i].item()\n",
    "    return pred\n",
    "\n",
    "group = group.assign(pred_B0=group.apply( lambda r: fun(r,0) ,axis=1))\n",
    "group = group.assign(pred_gfr_x=group.apply( lambda r: fun(r,1) ,axis=1))\n",
    "group = group.assign(pred_gfr_y=group.apply( lambda r: fun(r,2) ,axis=1))\n",
    "\n",
    "group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
